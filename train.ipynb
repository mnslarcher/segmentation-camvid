{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from prepare_data import prepare_data\n",
    "from segmentation.datasets import SegmentationDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/CamVid/preproc/\"\n",
    "CATEGORIES = [\n",
    "    \"background\",\n",
    "    \"sky\", \n",
    "    \"building\", \n",
    "    \"pole\", \n",
    "    \"road\", \n",
    "    \"pavement\", \n",
    "    \"tree\", \n",
    "    \"signsymbol\", \n",
    "    \"fence\", \n",
    "    \"car\", \n",
    "    \"pedestrian\", \n",
    "    \"bicyclist\", \n",
    "    \"unlabelled\"\n",
    "]\n",
    "CATEGORY_IDS = range(len(CATEGORIES))\n",
    "NUM_WORKERS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_dir = os.path.join(DATA_DIR, \"images\", \"train\")\n",
    "masks_train_dir = os.path.join(DATA_DIR, \"masks\", \"train\")\n",
    "\n",
    "images_val_dir = os.path.join(DATA_DIR, \"images\", \"val\")\n",
    "masks_val_dir = os.path.join(DATA_DIR, \"masks\", \"val\")\n",
    "\n",
    "images_test_dir = os.path.join(DATA_DIR, \"images\", \"test\")\n",
    "masks_test_dir = os.path.join(DATA_DIR, \"masks\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augments(size=512):\n",
    "    transforms = [\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "        \n",
    "        A.LongestMaxSize(size),\n",
    "        A.PadIfNeeded(size, size, border_mode=cv2.BORDER_CONSTANT),\n",
    "\n",
    "#         A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
    "#         A.RandomCrop(height=320, width=320, always_apply=True),\n",
    "\n",
    "        A.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        A.IAAPerspective(p=0.5),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightness(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.IAASharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomContrast(p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return A.Compose(transforms)\n",
    "\n",
    "\n",
    "def get_val_augments(size=512):\n",
    "    transforms = [\n",
    "        A.LongestMaxSize(size),\n",
    "        A.PadIfNeeded(size, size, border_mode=cv2.BORDER_CONSTANT),\n",
    "    ]\n",
    "    return A.Compose(transforms)\n",
    "\n",
    "def to_float32(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "def to_int64(x, **kwargs):\n",
    "    return x.astype(\"int64\")\n",
    "\n",
    "def get_preprocess(preprocessing_fn):\n",
    "    transforms = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "#         A.Lambda(image=to_float32, mask=to_float32),\n",
    "        A.Lambda(image=to_float32, mask=to_int64),\n",
    "    ]\n",
    "    return A.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_NAME = \"resnet34\"\n",
    "ENCODER_DEPTH = 5\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "ENCODER_OUTPUT_STRIDE = 16\n",
    "DECODER_CHANNELS = 256\n",
    "DECODER_ATROUS_RATES = (12, 24, 36)\n",
    "IN_CHANNELS = 3\n",
    "ACTIVATION = None # could be None for logits or \"softmax2d\" for multicalss segmentation\n",
    "UPSAMPLING = 4\n",
    "AUX_PARAMS = None\n",
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER_NAME,\n",
    "    encoder_depth=ENCODER_DEPTH,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    encoder_output_stride=ENCODER_OUTPUT_STRIDE,\n",
    "    decoder_channels=DECODER_CHANNELS,\n",
    "    decoder_atrous_rates=DECODER_ATROUS_RATES,\n",
    "    in_channels=IN_CHANNELS,\n",
    "    classes=len(CATEGORY_IDS),\n",
    "    activation=ACTIVATION,\n",
    "    upsampling=UPSAMPLING,\n",
    "    aux_params=AUX_PARAMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER_NAME, ENCODER_WEIGHTS)\n",
    "\n",
    "train_dataset = SegmentationDataset(\n",
    "    images_dir=images_train_dir,\n",
    "    masks_dir=masks_train_dir,\n",
    "    category_ids=CATEGORY_IDS,\n",
    "    augments=get_train_augments(),\n",
    "    preprocess=get_preprocess(preprocessing_fn),\n",
    ")\n",
    "val_dataset = SegmentationDataset(\n",
    "    images_dir=images_val_dir,\n",
    "    masks_dir=masks_val_dir,\n",
    "    category_ids=CATEGORY_IDS,\n",
    "    augments=get_val_augments(),\n",
    "    preprocess=get_preprocess(preprocessing_fn),\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolbelt import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.DiceLoss(mode=\"multiclass\")\n",
    "loss.__name__ = \"DiceLoss\"\n",
    "# cross-entropy incosistenza tra il formato che vuole e quello della previsione\n",
    "# metrics = [\n",
    "#     smp.utils.metrics.IoU(threshold=0.5),\n",
    "# ]\n",
    "metrics = []\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-newman",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "\n",
    "for i in range(0, 40):\n",
    "    \n",
    "    print(\"\\nEpoch: {}\".format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "#     valid_logs = valid_epoch.run(val_loader)\n",
    "    \n",
    "#     # do something (save model, change lr, etc.)\n",
    "#     if max_score < valid_logs[\"iou_score\"]:\n",
    "#         max_score = valid_logs[\"iou_score\"]\n",
    "#         torch.save(model, \"./best_model.pth\")\n",
    "#         print(\"Model saved!\")\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0][\"lr\"] = 1e-5\n",
    "        print(\"Decrease decoder learning rate to 1e-5!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.optim import SGD\n",
    "\n",
    "from segmentation.optim import PolyLR\n",
    "\n",
    "\n",
    "class SegmentationModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        loss,\n",
    "        lr=0.007,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.00004,\n",
    "        max_step=30000,\n",
    "        power=0.9,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.max_step = max_step\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss(out, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            momentum=self.momentum,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        scheduler = PolyLR(optimizer, self.max_step, power=self.power)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(gpus=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
